{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "import argparse\n",
    "import joblib\n",
    "from joblib import Parallel,delayed\n",
    "from joblib import parallel_backend\n",
    "from pandarallel import pandarallel\n",
    "from  tqdm import tqdm\n",
    "pandarallel.initialize()\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "\n",
    "# ---------------------------------------------\n",
    "USE_TFIDF = True\n",
    "USE_doc2vec = True\n",
    "model_pkl_dir = 'model_pkl_dir'\n",
    "mapping_df_dir = 'mapping_data_dir'\n",
    "\n",
    "# ---------------------------------------------\n",
    "def read_vectors_from_file(_typeID, _date):\n",
    "    global model_pkl_dir\n",
    "    if _typeID == 'LongFormer':\n",
    "        fname = os.path.join(model_pkl_dir, \"doc_id2sBertEmb_{}.pkl\".format(_date))\n",
    "    elif _typeID == 'sBert':\n",
    "        fname = os.path.join(model_pkl_dir,\"doc_id2LongFormerEmb_{}.pkl\".format(_date))\n",
    "    elif _typeID == 'tfidf':\n",
    "        fname =  os.path.join(model_pkl_dir, \"doc_id2tfidfEmb_{}.pkl\".format(_date))\n",
    "    elif _typeID == 'doc2vec':\n",
    "        fname =  os.path.join(model_pkl_dir, \"doc_id2doc2vecEmb_{}.pkl\".format(_date))\n",
    "       \n",
    "    with open(fname,'rb') as fh:\n",
    "        vec = pickle.load(fh)\n",
    "        vec = np.array(list(vec.values()))\n",
    "        return vec\n",
    "\n",
    "        \n",
    "def read_indices_from_file( _typeID, date):\n",
    "    global model_pkl_dir\n",
    "    filename = os.path.join(model_pkl_dir ,'faiss_index_{}_{}'.format(_typeID, date))\n",
    "    index = faiss.read_index(filename)\n",
    "    return index\n",
    "    \n",
    "    \n",
    "class query_doc:\n",
    "    def __init__(self, date_str, nprobe=25):\n",
    "        self.date_str = date_str\n",
    "        self.nprobe = nprobe\n",
    "        self.df_Mapping = pd.read_csv(os.path.join(mapping_df_dir, 'mapping_data_{}.csv'.format(date_str)),index_col=None)\n",
    "        \n",
    "        self.index_tfidf = None\n",
    "        self.index_doc2vec = None\n",
    "\n",
    "        self.vectors_tfidf = None \n",
    "        self.vectors_doc2vec = None\n",
    "        \n",
    "        self.index_tfidf = read_indices_from_file('tfidf', date_str)    \n",
    "        self.index_tfidf.nprobe = nprobe\n",
    "\n",
    "        self.index_doc2vec = read_indices_from_file('doc2vec',date_str)\n",
    "        self.index_doc2vec.nprobe = nprobe\n",
    "        \n",
    "        self.vectors_tfidf = read_vectors_from_file('tfidf', date_str)  \n",
    "        self.vectors_doc2vec = read_vectors_from_file('doc2vec', date_str)  \n",
    "        \n",
    "        return\n",
    "\n",
    "        \n",
    "    def query(\n",
    "        self,\n",
    "        doc_ID = None, \n",
    "        synID = None,\n",
    "        find_NN = 10,\n",
    "        min_count_threshold = 2,\n",
    "        n_probe = 20\n",
    "    ):\n",
    "        obj_list = [self.index_tfidf, self.index_doc2vec]\n",
    "        vec_list = [self.vectors_tfidf, self.vectors_doc2vec]\n",
    "        result = []\n",
    "\n",
    "        if doc_ID is None and synID is None :\n",
    "            return\n",
    "        if doc_ID is not None:\n",
    "            _tmp_ = df_Mapping.loc[(df_Mapping['id']==doc_ID)]\n",
    "            synID = _tmp_['synID'].values[0]\n",
    "\n",
    "        _type_of_index = ['tfidf', 'doc2vec']\n",
    "        i = 0 \n",
    "        for _index,_vector in zip(obj_list, vec_list):\n",
    "            i+=1\n",
    "            if _index is None: continue\n",
    "            _index.nprobe = n_probe\n",
    "            D, I = _index.search(\n",
    "                np.array([_vector[synID]]).astype(np.float32),\n",
    "                find_NN\n",
    "            ) \n",
    "            result.extend(I[0][1:])\n",
    "\n",
    "        counter = Counter(result)\n",
    "        filtered = [ k for k,v in counter.items() if v >= min_count_threshold and k >-1 and k!=synID]    \n",
    "        return filtered\n",
    "\n",
    "def test(input_syn_id=32):\n",
    "    query_obj = query_doc('2020-12-10')\n",
    "    query_obj.query( synID = 32 , min_count_threshold = 2)\n",
    "   \n",
    "    res = query_obj.query(\n",
    "        synID = input_syn_id, \n",
    "        find_NN = 10,\n",
    "        min_count_threshold = 2,\n",
    "        n_probe = 20\n",
    "    )\n",
    "    print(input_syn_id, res)\n",
    "    for r in [input_syn_id] + res:\n",
    "        print(query_obj.df_Mapping.loc[query_obj.df_Mapping['synID']==r].title)\n",
    "    return   \n",
    "\n",
    "test(250)\n",
    "\n",
    "test(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
