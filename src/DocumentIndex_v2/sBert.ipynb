{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#  Input should be a list of sentences.\n",
    "# =============================\n",
    "\n",
    "def get_doc_emb(doc_text):\n",
    "    global tokenizer\n",
    "    global model\n",
    "    global DEVICE\n",
    "    \n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt').to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    # Take a mean of the sentences \n",
    "    return torch.mean(sentence_embeddings,dim=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2809e-01,  3.5750e-01,  4.1518e-01,  1.6900e-01,  8.3606e-02,\n",
       "         7.3211e-02, -1.5879e-01, -1.9684e-02, -1.9021e-01, -2.7730e-01,\n",
       "        -6.0024e-01,  3.9147e-01,  1.7148e-01, -1.0057e-01,  2.3102e-02,\n",
       "        -2.5747e-01, -8.4040e-02, -2.2876e-01,  1.7119e-01, -4.9106e-01,\n",
       "        -2.7618e-01,  6.3767e-03, -9.7387e-01, -7.8169e-01,  7.6970e-01,\n",
       "        -3.0025e-01,  1.9407e-01, -1.6629e-01, -8.6983e-01,  2.1038e-01,\n",
       "        -3.9116e-01,  9.4829e-02,  8.0652e-01, -2.1120e-01, -2.6125e-01,\n",
       "        -6.1115e-02,  5.6831e-01, -5.0122e-02,  1.3548e-01, -6.2303e-01,\n",
       "         4.1839e-01, -1.0829e-01,  2.7848e-01, -6.3659e-02, -1.1550e+00,\n",
       "        -3.1414e-01, -6.4800e-01, -3.0956e-02, -1.4968e-02, -1.5882e-01,\n",
       "        -8.7936e-01,  2.1938e-01,  2.3919e-01,  1.1233e-01, -6.9157e-01,\n",
       "         1.7533e-01,  5.2621e-01, -5.2849e-01, -6.3219e-02,  7.1167e-02,\n",
       "        -2.8902e-01, -2.2216e-01,  2.6226e-01,  3.8673e-01, -4.7657e-01,\n",
       "         1.8633e-01,  4.0936e-01, -2.1928e-01, -9.4506e-01,  2.0684e-01,\n",
       "         5.7409e-02, -6.4003e-01, -3.7691e-01,  3.6862e-01, -4.3532e-01,\n",
       "        -1.2374e-01, -2.2125e-01,  6.1222e-01, -1.2133e-01,  2.4113e-01,\n",
       "        -3.9677e-01,  3.0413e-01,  4.9852e-01, -3.1121e-01,  4.6265e-01,\n",
       "        -3.5777e-02,  4.3922e-01,  2.3144e-01, -7.5498e-01,  5.0546e-01,\n",
       "         2.5258e-01,  3.5650e-02, -2.6339e-01, -4.0907e-02,  9.8623e-02,\n",
       "        -1.8633e-01,  7.2546e-03,  3.8269e-02,  1.3493e-01,  1.3141e-01,\n",
       "        -5.8639e-01, -1.4715e-01,  2.0848e-01, -3.0756e-01, -3.5008e-01,\n",
       "         7.7425e-02, -2.2399e-01, -2.0135e-01, -2.5959e-01,  4.9889e-01,\n",
       "         1.4601e-01,  1.1928e-01,  2.2917e-01,  1.0394e-01,  1.3763e-01,\n",
       "         2.4497e-02, -9.5215e-02,  7.7047e-01,  1.2686e-02,  4.0828e-01,\n",
       "         4.1700e-02,  2.9382e-01,  3.2082e-01, -4.6660e-01,  3.1857e-01,\n",
       "        -1.5766e-01,  3.7380e-01,  5.1410e-01,  4.6905e-02, -4.1248e-01,\n",
       "         3.2084e-01,  1.0542e-01,  4.4218e-01, -5.1905e-01,  1.9483e-01,\n",
       "        -1.8159e-02,  1.3666e-01, -3.3163e-01, -2.6346e-01, -2.4341e-01,\n",
       "        -4.0884e-01,  2.2958e-01,  4.1439e-01, -9.6358e-02,  6.4361e-02,\n",
       "        -2.9050e-02,  9.8033e-02, -6.8045e-01, -5.0814e-01,  4.7891e-01,\n",
       "        -2.7262e-01,  5.6949e-01, -8.7660e-01, -3.2492e-01, -4.2868e-01,\n",
       "         1.2254e-01, -2.5788e-01,  6.5774e-02,  1.4758e-01,  4.2981e-01,\n",
       "         3.9280e-01,  8.4495e-01, -3.0868e-01, -2.7860e-01, -1.8726e-01,\n",
       "        -2.4090e-01, -1.6534e-01, -3.7140e-01, -4.5845e-01, -1.9112e-01,\n",
       "         2.8337e-01,  1.6156e-01,  4.8843e-01,  2.6982e-02, -3.3119e-01,\n",
       "        -4.4472e-01,  1.1887e-01,  3.8970e-01,  3.5318e-01, -9.1883e-01,\n",
       "         3.8409e-01,  4.0065e-02,  3.7440e-01, -4.0393e-01, -7.5999e-01,\n",
       "        -3.5280e-01,  4.3797e-01, -3.1931e-01,  1.5733e-01, -2.3457e-01,\n",
       "        -3.1015e-01, -1.7616e-01, -2.5086e-01, -7.9789e-01,  3.6920e-01,\n",
       "         1.3366e-01, -7.8963e-01,  5.1933e-01,  7.2730e-02,  7.4746e-02,\n",
       "        -4.5725e-02, -2.3724e-01,  4.0487e-01, -4.9807e-01,  3.3968e-01,\n",
       "         5.3135e-01, -4.3749e-01,  5.6975e-01, -5.9851e-01,  1.8208e-01,\n",
       "        -5.9856e-01,  6.6290e-01,  6.0163e-01,  2.2780e-01,  6.6806e-02,\n",
       "        -1.9477e-01,  1.3592e-01, -5.9106e-01,  6.0394e-02,  5.5077e-01,\n",
       "         6.4004e-01, -1.9635e-01, -1.2654e-02,  2.7578e-01, -7.5191e-01,\n",
       "         5.5866e-01,  7.6403e-01,  5.1548e-02,  1.0474e+00,  2.0136e-01,\n",
       "         4.1114e-01, -1.5362e-01, -2.9667e-01,  4.8515e-01, -2.2429e-02,\n",
       "        -1.7478e-01,  1.1045e-01, -1.9402e-02,  1.9158e-01,  2.9082e-01,\n",
       "         6.3383e-01,  9.1628e-01, -2.0783e-02, -7.4574e-02, -5.8562e-01,\n",
       "        -4.6066e-01,  4.6028e-01,  7.6700e-02, -5.7969e-01,  3.9274e-02,\n",
       "        -1.0895e-01, -2.9371e-01,  3.4328e-01, -5.9657e-01,  2.6689e-01,\n",
       "        -1.6598e-01, -2.7513e-01,  5.4071e-02,  9.4046e-02, -1.2838e-01,\n",
       "        -2.2306e-02, -7.6208e-01, -2.7686e-01,  2.1820e-01, -1.6461e-01,\n",
       "        -4.9865e-01, -2.4989e-01, -9.4388e-02, -6.0222e-02,  2.5812e-01,\n",
       "         1.2180e-01, -2.4403e-01, -1.1292e-01,  3.7806e-02,  9.4726e-02,\n",
       "        -5.8898e-01,  6.9062e-01, -1.4341e-01, -3.8249e-01, -2.2774e-01,\n",
       "        -5.3825e-01, -2.9716e-01, -8.9649e-01,  3.2383e-01,  2.1374e-01,\n",
       "        -2.2463e-01,  4.4096e-01, -7.3995e-01, -3.0644e-01,  2.3853e-02,\n",
       "        -7.2907e-02,  1.7867e-01, -3.4355e-01, -3.7365e-02, -1.8004e-02,\n",
       "         2.9722e-01,  5.5216e-01, -3.6185e-01, -2.4369e-01, -3.6391e-01,\n",
       "        -1.7598e-01,  1.1011e-02, -3.7106e-01, -7.0671e-02, -4.1473e-01,\n",
       "         1.9741e-01,  1.1488e-01,  3.8481e-01, -1.6528e+00, -2.9294e-01,\n",
       "        -5.4222e-01, -3.7503e-02,  2.9574e-01, -2.1711e-03,  4.2094e-02,\n",
       "         4.7611e-01, -2.5325e-01,  6.0832e-01, -6.6955e-01, -9.9832e-01,\n",
       "        -4.5978e-01,  4.7877e-01,  2.5907e-01, -2.6492e-01,  4.5993e-02,\n",
       "        -7.2570e-02, -5.6838e-02,  6.2270e-01, -5.0731e-01, -2.1606e-01,\n",
       "         5.2294e-01,  2.2529e-01, -3.2173e-01,  1.9574e-01, -4.9810e-01,\n",
       "         5.0478e-01, -6.6087e-01, -4.1579e-01,  2.1982e-01, -4.0917e-01,\n",
       "        -1.0652e-01, -1.7023e-01, -3.5915e-01, -2.2718e-01,  7.7681e-01,\n",
       "         1.1025e-01,  1.5018e-01, -5.7352e-01,  1.9642e-01,  1.5214e-01,\n",
       "        -4.3263e-02, -4.6575e-01,  1.3941e-01,  1.3012e-01, -4.2644e-01,\n",
       "        -5.3708e-01,  2.7254e-01,  1.8136e-01, -7.1567e-01,  2.9278e-01,\n",
       "        -6.8965e-02,  9.7625e-02,  2.4874e-01, -4.0149e-01,  2.0814e-01,\n",
       "         1.1425e-01,  2.6337e-01,  2.2746e-01,  4.5136e-01, -1.3807e-01,\n",
       "         2.0450e-01,  2.0953e-04, -1.1699e-01, -1.3022e-02, -2.7451e-01,\n",
       "        -2.3607e-01,  8.3081e-02, -1.8322e-01,  1.2446e-01, -2.1810e-02,\n",
       "         2.8929e-02, -9.2458e-01,  3.9631e-01, -2.6123e-01,  5.3521e-01,\n",
       "         9.8559e-02,  2.6639e-01,  1.2841e-01, -2.2858e-01, -4.7681e-01,\n",
       "         5.6834e-01,  3.1172e-02,  4.1870e-01, -8.5657e-02, -2.7239e-01,\n",
       "        -5.8376e-01, -3.1092e-01, -3.0221e-01,  1.7433e-01, -3.4415e-01,\n",
       "        -4.0666e-02,  1.2077e-01,  6.7935e-01, -2.7059e-01,  1.1463e-01,\n",
       "        -7.0487e-02,  4.6038e-01, -2.7184e-01,  3.9197e-01, -7.8565e-01,\n",
       "        -1.7772e-01, -1.8360e-01, -2.1299e-01,  2.3671e-01, -1.0815e+00,\n",
       "         5.4343e-01,  5.3191e-01, -1.7877e-01, -5.8137e-01,  5.0748e-01,\n",
       "        -4.6844e-01, -5.5789e-01,  8.4914e-02,  4.8052e-01, -3.6559e-01,\n",
       "         9.7996e-02, -2.1363e-01,  5.0437e-02, -3.3217e-01, -1.6595e-01,\n",
       "        -2.9677e-01, -4.0429e-02, -6.5231e-01, -2.7034e-01,  6.0954e-01,\n",
       "        -2.5858e-01,  5.3493e-01, -3.4586e-01, -3.9805e-01, -1.6450e-01,\n",
       "        -2.5802e-01, -4.5709e-01,  3.7025e-01, -2.0379e-01, -1.7241e-01,\n",
       "         6.4070e-01,  9.6499e-02, -2.6870e-01,  2.7445e-01, -1.1706e-01,\n",
       "         3.8011e-01,  2.1131e-01, -1.7293e-02,  5.0775e-01,  3.1485e-01,\n",
       "        -2.7089e-01, -6.5446e-01, -3.8781e-01,  3.4793e-02, -4.3920e-01,\n",
       "        -6.6768e-02, -4.2832e-02, -1.2525e-01, -3.7169e-01,  2.1385e-01,\n",
       "         4.0073e-01, -2.9104e-01, -1.8677e-02,  2.7922e-01,  1.8156e-01,\n",
       "         1.4616e-01, -5.6664e-01,  1.5393e-01,  7.3944e-01,  5.3817e-01,\n",
       "         4.3800e-01, -1.0778e+00,  6.1423e-01, -6.6320e-01,  4.1122e-01,\n",
       "         4.6775e-02,  6.9985e-01,  2.3270e-01, -2.1068e-01,  7.2553e-02,\n",
       "         5.2165e-01,  1.3109e-01,  7.9609e-01,  3.8476e-01,  2.8424e-03,\n",
       "        -2.0748e-02,  2.1004e-01, -4.3726e-01, -3.0987e-01,  2.0449e-01,\n",
       "         1.0011e+00, -3.2222e-01, -1.8400e-01, -8.0001e-02,  4.9204e-02,\n",
       "         4.0950e-01,  4.0777e-01, -4.9888e-01, -5.3396e-01, -1.7562e-01,\n",
       "         8.1680e-01, -1.3933e-01, -6.1279e-01,  1.8371e-01,  2.9590e-01,\n",
       "        -3.1298e-01, -3.7086e-01,  3.4256e-01, -3.8063e-01, -4.6946e-02,\n",
       "         1.2800e-01,  1.2762e-01,  5.6921e-02,  1.7051e-01, -6.4591e-01,\n",
       "        -2.2495e-01, -3.8978e-01,  8.2610e-04, -6.7254e-01, -1.1422e-01,\n",
       "         6.3556e-02,  4.6941e-01, -6.9393e-02,  5.0165e-01,  1.7252e-01,\n",
       "         1.8603e-01,  3.9022e-01,  2.8983e-02,  4.2625e-01, -2.7929e-01,\n",
       "         4.7995e-01, -4.8762e-01,  2.7882e-02,  1.0008e+00,  6.6041e-02,\n",
       "         1.7199e-01,  2.6405e-01, -2.9502e-01, -1.0450e+00, -6.8272e-01,\n",
       "        -2.2037e-02,  3.6306e-01, -5.4183e-01, -8.6055e-02, -3.8386e-02,\n",
       "        -1.0405e-01, -8.1335e-02,  1.5306e-01,  3.6402e-01, -7.5393e-02,\n",
       "        -4.5453e-01, -5.1971e-01,  7.3866e-01,  1.5248e-01,  4.2525e-01,\n",
       "         3.6120e-01,  3.3041e-01, -2.2400e-01,  8.2116e-01, -4.0278e-01,\n",
       "        -4.5539e-01, -3.6005e-01,  1.8043e-01,  2.2366e-01,  2.1636e-01,\n",
       "         1.1657e-01, -2.9601e-02,  7.1437e-01,  6.5257e-01, -7.6245e-01,\n",
       "        -3.3202e-01,  3.1337e-01, -6.4726e-01,  3.3657e-05, -1.4236e-01,\n",
       "         3.2665e-02,  5.2408e-01,  1.9623e-01, -1.5097e-01,  2.3160e-01,\n",
       "         7.1377e-01,  4.6212e-01,  8.9159e-02, -2.8287e-01,  2.1583e-01,\n",
       "         3.2542e-01,  1.2043e-01,  1.4658e-01,  6.9358e-02,  2.6898e-01,\n",
       "         1.8053e-01,  1.6989e-02,  1.1498e+00, -1.3669e-01,  5.3252e-01,\n",
       "         5.1234e-02, -3.4750e-01, -6.3548e-01,  1.3490e-01,  9.7678e-02,\n",
       "         4.2977e-01,  2.5420e-01,  1.1405e-01, -4.5058e-01, -5.4074e-02,\n",
       "         7.4804e-01, -8.2746e-01, -2.0897e-01, -2.9340e-01,  8.3672e-02,\n",
       "        -3.9690e-01,  2.5985e-02,  3.1538e-01,  3.6368e-01,  2.1583e-01,\n",
       "        -1.4221e-01,  1.1067e-01, -5.5418e-01, -7.8992e-01, -7.7266e-02,\n",
       "        -9.7688e-01,  5.9327e-01,  3.6661e-02, -3.7205e-01,  7.0144e-02,\n",
       "         2.8547e-01,  2.4181e-02, -1.0037e+00,  4.9505e-01, -2.8817e-02,\n",
       "         9.9029e-01, -4.3246e-01, -1.0673e-01,  2.0293e-01,  2.7074e-01,\n",
       "        -4.3058e-01, -4.1550e-01, -1.2955e-01, -6.3108e-01,  5.0211e-01,\n",
       "         3.7022e-01,  2.2611e-01,  2.3258e-01,  1.1646e+00,  8.8734e-02,\n",
       "        -1.6863e-01,  1.4709e-01, -3.8910e-01, -1.6383e-01,  1.6220e-01,\n",
       "         4.8542e-01, -4.6719e-01,  8.1660e-01,  3.2028e-01,  2.7259e-01,\n",
       "         7.5868e-01, -6.2845e-02, -1.7325e-01, -1.8628e-01,  4.0945e-01,\n",
       "         1.4081e-01, -1.7685e-01,  1.6696e-02, -5.9100e-02,  4.4777e-01,\n",
       "        -3.7606e-01, -1.7063e-01,  3.2694e-01, -3.4808e-01,  4.8791e-01,\n",
       "         2.0548e-03,  9.6851e-01,  4.3188e-01, -2.0994e-01, -6.2273e-01,\n",
       "        -4.6814e-01,  1.4342e-01, -2.3867e-01, -1.5200e-02,  5.6872e-01,\n",
       "        -3.9084e-02, -2.3458e-01,  1.1252e-01,  2.1001e-02, -4.7346e-02,\n",
       "         2.7961e-01,  6.1030e-01, -3.7046e-01, -7.6587e-01, -2.2441e-01,\n",
       "         1.7561e-01, -4.2117e-02,  1.7668e-01, -5.0044e-01, -4.8248e-01,\n",
       "        -2.7761e-01,  2.4455e-01, -2.7187e-01,  1.7308e-01, -5.0628e-02,\n",
       "         1.7964e-01, -8.2121e-02,  6.6916e-04, -2.5727e-01, -3.3397e-03,\n",
       "         4.9623e-01,  3.1358e-01,  4.1861e-01,  6.1194e-01,  4.1687e-02,\n",
       "        -3.5622e-01,  1.5968e-01,  3.6953e-01,  5.2754e-01, -8.7193e-02,\n",
       "        -2.8319e-01,  1.0833e-01, -4.2087e-01, -1.8407e-01, -2.1569e-01,\n",
       "        -2.3450e-01,  1.5360e-01,  5.7520e-02, -3.8950e-01, -2.5351e-01,\n",
       "        -1.3031e-01,  9.4165e-02, -4.2433e-01,  2.0079e-01,  1.1138e-01,\n",
       "        -1.6925e-01, -6.1940e-01, -2.0140e-01, -5.0909e-01,  3.3131e-01,\n",
       "         2.2579e-01, -2.6300e-01, -2.0807e-01, -2.0168e-01, -2.6739e-01,\n",
       "         2.9619e-01,  3.1605e-01, -9.2067e-02, -6.5900e-01,  2.9359e-01,\n",
       "        -8.9541e-02,  7.2165e-02, -6.4759e-02,  2.7072e-01,  1.8401e-01,\n",
       "         7.3560e-02, -1.1419e+00, -2.1715e-01, -2.4090e-02, -2.3309e-01,\n",
       "        -4.3662e-01, -5.7215e-02, -3.8131e-01, -3.4764e-01,  1.5284e-01,\n",
       "        -8.3940e-02,  1.0768e-01,  5.1757e-01], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.',\n",
    "             'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "\n",
    "get_doc_emb(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f524114a610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pool_layer = torch.nn.AvgPool1d(model.embeddings.word_embeddings.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.stack( [sentence_embeddings,sentence_embeddings], dim=0),dim=-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
