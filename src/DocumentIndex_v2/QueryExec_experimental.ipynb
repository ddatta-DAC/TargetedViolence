{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "import argparse\n",
    "import joblib\n",
    "from joblib import Parallel,delayed\n",
    "from joblib import parallel_backend\n",
    "from pandarallel import pandarallel\n",
    "from  tqdm import tqdm\n",
    "pandarallel.initialize()\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "USE_TFIDF = True\n",
    "USE_sBert = False\n",
    "USE_Longformer = False\n",
    "USE_doc2vec = True\n",
    "# ---------------------------------------------\n",
    "date_str = '2020-12-10'\n",
    "\n",
    "N_PROBE = 100\n",
    "model_pkl_dir = 'model_pkl_dir'\n",
    "mapping_df_dir = 'mapping_data_dir'\n",
    "df_Mapping = pd.read_csv(os.path.join(mapping_df_dir, 'mapping_data_{}.csv'.format(date_str)),index_col=None)\n",
    "\n",
    "# choices : tfidf, sBert, LongFormer\n",
    "def read_indices_from_file(_typeID, date):\n",
    "    global model_pkl_dir\n",
    "    filename = os.path.join(model_pkl_dir ,'faiss_index_{}_{}'.format(_typeID, date))\n",
    "    index = faiss.read_index(filename)\n",
    "    return index\n",
    "\n",
    "# -------------------------------------\n",
    "# Vector returned is an ordered dict\n",
    "# choices : tfidf, sBert, LongFormer\n",
    "# -------------------------------------\n",
    "def read_vectors_from_file(_typeID, _date):\n",
    "    global model_pkl_dir\n",
    "    if _typeID == 'LongFormer':\n",
    "        fname = os.path.join(model_pkl_dir, \"doc_id2sBertEmb_{}.pkl\".format(_date))\n",
    "    elif _typeID == 'sBert':\n",
    "        fname = os.path.join(model_pkl_dir,\"doc_id2LongFormerEmb_{}.pkl\".format(_date))\n",
    "    elif _typeID == 'tfidf':\n",
    "        fname =  os.path.join(model_pkl_dir, \"doc_id2tfidfEmb_{}.pkl\".format(_date))\n",
    "    elif _typeID == 'doc2vec':\n",
    "        fname =  os.path.join(model_pkl_dir, \"doc_id2doc2vecEmb_{}.pkl\".format(_date))\n",
    "    print(fname)      \n",
    "    with open(fname,'rb') as fh:\n",
    "        vec = pickle.load(fh)\n",
    "        vec = np.array(list(vec.values()))\n",
    "        return vec\n",
    "\n",
    "index_sBert = None\n",
    "index_tfidf = None\n",
    "index_longformer = None\n",
    "index_doc2vec = None\n",
    "vectors_sBert = None\n",
    "vectors_longformer = None\n",
    "vectors_tfidf = None \n",
    "vectors_doc2vec = None\n",
    "\n",
    "def initialize(date_str):\n",
    "    global df_Mapping\n",
    "    global index_sBert\n",
    "    global index_tfidf\n",
    "    global index_longformer\n",
    "    global index_doc2vec\n",
    "    global vectors_longformer\n",
    "    global vectors_sBert\n",
    "    global vectors_tfidf\n",
    "    global vectors_doc2vec\n",
    "    global N_PROBE\n",
    "    global USE_TFIDF, USE_Longformer, USE_sBert\n",
    "    \n",
    "    if USE_sBert:\n",
    "        index_sBert = read_indices_from_file('sBert', date_str)\n",
    "        index_sBert.nprobe = N_PROBE\n",
    "    if USE_TFIDF:\n",
    "        index_tfidf = read_indices_from_file('tfidf', date_str)    \n",
    "        index_tfidf.nprobe = N_PROBE\n",
    "\n",
    "    if USE_Longformer:\n",
    "        index_longformer = read_indices_from_file('LongFormer',date_str)\n",
    "        index_longformer.nprobe = N_PROBE\n",
    "    if USE_doc2vec:\n",
    "        index_doc2vec = read_indices_from_file('doc2vec',date_str)\n",
    "        index_doc2vec.nprobe = N_PROBE\n",
    "\n",
    "    try:    \n",
    "        vectors_longformer = read_vectors_from_file('LongFormer',date_str )\n",
    "    except :\n",
    "        pass\n",
    "    try:\n",
    "        vectors_sBert = read_vectors_from_file('sBert', date_str)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        vectors_tfidf = read_vectors_from_file('tfidf', date_str)  \n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        vectors_doc2vec = read_vectors_from_file('doc2vec', date_str)  \n",
    "    except:\n",
    "        pass\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(\n",
    "    doc_ID =None, \n",
    "    synID = None,\n",
    "    find_NN = 20,\n",
    "    min_count_threshold = 1,\n",
    "    n_probe = 20\n",
    "  \n",
    "):\n",
    "    global df_Mapping\n",
    "    global index_sBert\n",
    "    global index_tfidf\n",
    "    global index_longformer\n",
    "    global vectors_longformer\n",
    "    global vectors_sBert\n",
    "    global vectors_tfidf\n",
    "    global index_doc2vec\n",
    "    global vectors_doc2vec\n",
    "    \n",
    "    obj_list = [index_tfidf, index_sBert, index_longformer,index_doc2vec]\n",
    "    vec_list = [vectors_tfidf, vectors_sBert, vectors_longformer,vectors_doc2vec]\n",
    "    result = []\n",
    "    \n",
    "    if doc_ID is None and synID is None :\n",
    "        return\n",
    "    if doc_ID is not None:\n",
    "        _tmp_ = df_Mapping.loc[(df_Mapping['id']==doc_ID)]\n",
    "        synID = _tmp_['synID'].values[0]\n",
    "        \n",
    "    _type_of_index = ['tfidf', 'bert', 'lf']\n",
    "    i = 0 \n",
    "    for _index,_vector in zip(obj_list, vec_list):\n",
    "        i+=1\n",
    "        if _index is None: \n",
    "            continue\n",
    "        _index.nprobe = n_probe\n",
    "        D, I = _index.search(\n",
    "            np.array([_vector[synID]]).astype(np.float32),\n",
    "            find_NN\n",
    "        ) \n",
    "        result.extend(I[0][1:])\n",
    "        \n",
    "    counter = Counter(result)\n",
    "    filtered = [ k for k,v in counter.items() if v >= min_count_threshold and k >-1 and k!=synID]    \n",
    "    return filtered\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_pkl_dir/doc_id2sBertEmb_2020-12-10.pkl\n",
      "model_pkl_dir/doc_id2LongFormerEmb_2020-12-10.pkl\n",
      "model_pkl_dir/doc_id2tfidfEmb_2020-12-10.pkl\n",
      "model_pkl_dir/doc_id2doc2vecEmb_2020-12-10.pkl\n"
     ]
    }
   ],
   "source": [
    "initialize(date_str = date_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 [778]\n",
      "250    Whiteford tells Detroit Rep. who received raci...\n",
      "Name: title, dtype: object\n",
      "778    Whiteford tells Detroit Rep. who received raci...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "input_syn_id = 250\n",
    "res = query(\n",
    "    synID = input_syn_id, \n",
    "    find_NN = 10,\n",
    "    min_count_threshold = 2,\n",
    "    n_probe = 20\n",
    ")\n",
    "print(input_syn_id, res)\n",
    "for r in [input_syn_id] + res:\n",
    "    print(df_Mapping.loc[df_Mapping['synID']==r].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [490, 16]\n",
      "100    Protesters descend on Secretary of State Jocel...\n",
      "Name: title, dtype: object\n",
      "490    Armed Thugs Showed Up at the House of Michigan...\n",
      "Name: title, dtype: object\n",
      "16    Armed Thugs Showed Up at the House of Michigan...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "input_syn_id = 100\n",
    "res = query(\n",
    "    synID = input_syn_id, \n",
    "    find_NN = 10,\n",
    "    min_count_threshold = 2,\n",
    "    n_probe = 20\n",
    ")\n",
    "print(input_syn_id, res)\n",
    "for r in [input_syn_id] + res:\n",
    "    print(df_Mapping.loc[df_Mapping['synID']==r].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [511, 1652]\n",
      "32    Seattle mayor Jenny Durkan won`t seek reelecti...\n",
      "Name: title, dtype: object\n",
      "511    Seattle mayor Jenny Durkan won`t seek reelecti...\n",
      "Name: title, dtype: object\n",
      "1652    Seattle mayor Jenny Durkan won`t seek reelecti...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "input_syn_id = 32\n",
    "res = query(\n",
    "    synID = input_syn_id, \n",
    "    find_NN = 10,\n",
    "    min_count_threshold = 2,\n",
    "    n_probe = 20\n",
    ")\n",
    "print(input_syn_id, res)\n",
    "for r in [input_syn_id] + res:\n",
    "    print(df_Mapping.loc[df_Mapping['synID']==r].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 [1002]\n",
      "150    Stock market rally amid COVID-19 creates disto...\n",
      "Name: title, dtype: object\n",
      "1002    Stock market rally amid COVID-19 creates disto...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "input_syn_id = 150\n",
    "res = query(\n",
    "    synID = input_syn_id, \n",
    "    find_NN = 10,\n",
    "    min_count_threshold = 2,\n",
    "    n_probe = 20\n",
    ")\n",
    "print(input_syn_id, res)\n",
    "for r in [input_syn_id] + res:\n",
    "    print(df_Mapping.loc[df_Mapping['synID']==r].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
